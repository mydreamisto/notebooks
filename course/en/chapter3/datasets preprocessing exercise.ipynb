{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8i6FeSZ1/uS/TP3XK3vuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mydreamisto/notebooks/blob/main/datasets_processing_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0TPAWNDutpj"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_dataset = load_dataset(\"gimmaru/glue-sst2\")"
      ],
      "metadata": {
        "id": "PAosAhEOveNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_validation_dataset = raw_dataset[\"validation\"]"
      ],
      "metadata": {
        "id": "rdFuOCSav4ja"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_validation_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v08xoatHv82N",
        "outputId": "1fd87b28-e11a-4faf-d510-9576a9750818"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': 'it gets onto the screen just about as much of the novella as one could reasonably expect , and is engrossing and moving in its own right . ',\n",
              " 'label': 1,\n",
              " 'idx': 726}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_validation_dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N3nwU4-wDXi",
        "outputId": "444ffacb-b3cf-4f93-b8a3-7ce8f10e181e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['negative', 'positive'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "IFqF_l9-wre0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "  return tokenizer(example[\"sentence\"], truncation = True)\n",
        "tokenized_dataset = raw_dataset.map(tokenize_function, batched = True)"
      ],
      "metadata": {
        "id": "lhofHutkwZi1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)"
      ],
      "metadata": {
        "id": "GNw5RL8VxwzK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = tokenized_dataset[\"validation\"][:8]\n",
        "# 这是一个字典推导式。它遍历 samples 中的每一个键值对（使用 items() 方法），并对键 k 和值 v 进行筛选。\n",
        "# if k not in [\"sentence\", \"idx\"] 是一个条件判断，只有当键 k 不在列表 [\"sentence\", \"idx\"] 中时，才将该键值对包含在新的字典 samples 中。\n",
        "# sentence 通常是原始的文本字符串。在深度学习中，模型通常需要将输入数据表示为张量（tensors），而不能直接处理字符串。\n",
        "# 对于模型训练来说，idx 可能只是一个样本的索引，在模型训练过程中通常不是必需的输入。\n",
        "# 将这些元素排除是因为它们无法直接作为张量输入到模型中进行计算。\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"sentence\", \"idx\"]}\n",
        "[len(x) for x in samples[\"input_ids\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufBrWLYL1i__",
        "outputId": "a9e9b08f-800d-4478-e0e9-1967046103ba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32, 24, 30, 40, 42, 16, 16, 15]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator(samples)\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMdZGzyd2Z4F",
        "outputId": "da12938e-117b-45e6-ed08-bae803375eee"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': torch.Size([8, 42]),\n",
              " 'token_type_ids': torch.Size([8, 42]),\n",
              " 'attention_mask': torch.Size([8, 42]),\n",
              " 'labels': torch.Size([8])}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}
